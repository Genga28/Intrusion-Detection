{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmyt2eefonA_",
        "outputId": "0da15de4-cf02-4c19-8bb3-512eb5e50a1b"
      },
      "outputs": [],
      "source": [
        "# import relevant modules\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import imblearn\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(threshold=np.inf, linewidth=np.nan)\n",
        "np.set_printoptions(precision=3)\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "print(\"pandas : {0}\".format(pd.__version__))\n",
        "print(\"numpy : {0}\".format(np.__version__))\n",
        "print(\"matplotlib : {0}\".format(matplotlib.__version__))\n",
        "print(\"seaborn : {0}\".format(sns.__version__))\n",
        "print(\"sklearn : {0}\".format(sklearn.__version__))\n",
        "print(\"imblearn : {0}\".format(imblearn.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "st.set_page_config(page_title=\"Intrusion detection\", page_icon=\"::\", layout=\"wide\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIbllYKCouEo"
      },
      "outputs": [],
      "source": [
        "# Dataset field names\n",
        "datacols = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"attack\", \"last_flag\"]\n",
        "\n",
        "# Load NSL_KDD train dataset\n",
        "dfkdd_train = pd.read_table(\"KDDTrain.txt\", sep=\",\", names=datacols) # change path to where the dataset is located.\n",
        "dfkdd_train = dfkdd_train.iloc[:,:-1] # removes an unwanted extra field\n",
        "\n",
        "# Load NSL_KDD test dataset\n",
        "dfkdd_test = pd.read_table(\"KDDTest.txt\", sep=\",\", names=datacols)\n",
        "dfkdd_test = dfkdd_test.iloc[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "PkxikiFwqZhx",
        "outputId": "bf23c819-c7a8-4435-f0c7-f3fbf39ec9c7"
      },
      "outputs": [],
      "source": [
        "# View train data\n",
        "dfkdd_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF_xCOd6qS1_",
        "outputId": "6fda666c-bff6-4f4d-f646-97eb614efebe"
      },
      "outputs": [],
      "source": [
        "# train set dimension\n",
        "print('Train set dimension: {} rows, {} columns'.format(dfkdd_train.shape[0], dfkdd_train.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "13wfJsjZqddT",
        "outputId": "737c05c3-d110-4a84-a94b-d38736dfcf34"
      },
      "outputs": [],
      "source": [
        "# View test data\n",
        "dfkdd_test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neQnjED1qf-N",
        "outputId": "dca344d1-d532-4199-b455-6a86d09460a0"
      },
      "outputs": [],
      "source": [
        "# test set dimension\n",
        "print('Test set dimension: {} rows, {} columns'.format(dfkdd_test.shape[0], dfkdd_test.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp2-YUPAqk0l"
      },
      "outputs": [],
      "source": [
        "mapping = {'ipsweep': 'Probe','satan': 'Probe','nmap': 'Probe','portsweep': 'Probe','saint': 'Probe','mscan': 'Probe',\n",
        "        'teardrop': 'DoS','pod': 'DoS','land': 'DoS','back': 'DoS','neptune': 'DoS','smurf': 'DoS','mailbomb': 'DoS',\n",
        "        'udpstorm': 'DoS','apache2': 'DoS','processtable': 'DoS',\n",
        "        'perl': 'U2R','loadmodule': 'U2R','rootkit': 'U2R','buffer_overflow': 'U2R','xterm': 'U2R','ps': 'U2R',\n",
        "        'sqlattack': 'U2R','httptunnel': 'U2R',\n",
        "        'ftp_write': 'R2L','phf': 'R2L','guess_passwd': 'R2L','warezmaster': 'R2L','warezclient': 'R2L','imap': 'R2L',\n",
        "        'spy': 'R2L','multihop': 'R2L','named': 'R2L','snmpguess': 'R2L','worm': 'R2L','snmpgetattack': 'R2L',\n",
        "        'xsnoop': 'R2L','xlock': 'R2L','sendmail': 'R2L',\n",
        "        'normal': 'Normal'\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HACt7F8Iqnof"
      },
      "outputs": [],
      "source": [
        "# Apply attack class mappings to the dataset\n",
        "dfkdd_train['attack_class'] = dfkdd_train['attack'].apply(lambda v: mapping[v])\n",
        "dfkdd_test['attack_class'] = dfkdd_test['attack'].apply(lambda v: mapping[v])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwPY1WStqqnP"
      },
      "outputs": [],
      "source": [
        "# Drop attack field from both train and test data\n",
        "dfkdd_train.drop(['attack'], axis=1, inplace=True)\n",
        "dfkdd_test.drop(['attack'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "NvQG9kFqqqwi",
        "outputId": "f076585c-79fa-400a-e917-bbc5064f7110"
      },
      "outputs": [],
      "source": [
        "# View top 3 train data \n",
        "dfkdd_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "NjA6xNdbqqzk",
        "outputId": "354dfc2a-87ee-4fb6-a3ee-3fed275c06d6"
      },
      "outputs": [],
      "source": [
        "# Descriptive statistics\n",
        "dfkdd_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UZAXF66qq1S",
        "outputId": "8d495f60-2d9f-490f-ed9f-260cee8a4017"
      },
      "outputs": [],
      "source": [
        "dfkdd_train['num_outbound_cmds'].value_counts()\n",
        "dfkdd_test['num_outbound_cmds'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIv5Zh78qq3y"
      },
      "outputs": [],
      "source": [
        "# 'num_outbound_cmds' field has all 0 values. Hence, it will be removed from both train and test dataset since it is a redundant field.\n",
        "dfkdd_train.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
        "dfkdd_test.drop(['num_outbound_cmds'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6nfz8QVhqq5_",
        "outputId": "983dbafb-8ce9-40e3-f1dc-cc79c0644cd9"
      },
      "outputs": [],
      "source": [
        "# Attack Class Distribution\n",
        "attack_class_freq_train = dfkdd_train[['attack_class']].apply(lambda x: x.value_counts())\n",
        "attack_class_freq_test = dfkdd_test[['attack_class']].apply(lambda x: x.value_counts())\n",
        "attack_class_freq_train['frequency_percent_train'] = round((100 * attack_class_freq_train / attack_class_freq_train.sum()),2)\n",
        "attack_class_freq_test['frequency_percent_test'] = round((100 * attack_class_freq_test / attack_class_freq_test.sum()),2)\n",
        "\n",
        "attack_class_dist = pd.concat([attack_class_freq_train,attack_class_freq_test], axis=1) \n",
        "attack_class_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "NCBzxPgwqq9W",
        "outputId": "7b564b37-cefb-4ee2-bf25-8a5341a34413"
      },
      "outputs": [],
      "source": [
        "# Attack class bar plot\n",
        "plot = attack_class_dist[['frequency_percent_train', 'frequency_percent_test']].plot(kind=\"bar\");\n",
        "plot.set_title(\"Attack Class Distribution\", fontsize=20);\n",
        "plot.grid(color='lightgray', alpha=0.5);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "in_u3FGzrA9P",
        "outputId": "95cf2173-10a0-494a-d9ae-22a65779ae6e"
      },
      "outputs": [],
      "source": [
        "dfkdd_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_tx2ltJrA_q"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
        "cols = dfkdd_train.select_dtypes(include=['float64','int64']).columns\n",
        "sc_train = scaler.fit_transform(dfkdd_train.select_dtypes(include=['float64','int64']))\n",
        "sc_test = scaler.fit_transform(dfkdd_test.select_dtypes(include=['float64','int64']))\n",
        "\n",
        "# turn the result back to a dataframe\n",
        "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
        "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP8oqgS_rBCL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# extract categorical attributes from both training and test sets \n",
        "cattrain = dfkdd_train.select_dtypes(include=['object']).copy()\n",
        "cattest = dfkdd_test.select_dtypes(include=['object']).copy()\n",
        "\n",
        "# encode the categorical attributes\n",
        "traincat = cattrain.apply(encoder.fit_transform)\n",
        "testcat = cattest.apply(encoder.fit_transform)\n",
        "\n",
        "# separate target column from encoded data \n",
        "enctrain = traincat.drop(['attack_class'], axis=1)\n",
        "enctest = testcat.drop(['attack_class'], axis=1)\n",
        "\n",
        "cat_Ytrain = traincat[['attack_class']].copy()\n",
        "cat_Ytest = testcat[['attack_class']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAXBfasZrBEf",
        "outputId": "dc28d0a6-b7a3-4835-b37b-26956ef67968"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler \n",
        "from collections import Counter\n",
        "\n",
        "# define columns and extract encoded train set for sampling \n",
        "sc_traindf = dfkdd_train.select_dtypes(include=['float64','int64'])\n",
        "refclasscol = pd.concat([sc_traindf, enctrain], axis=1).columns\n",
        "refclass = np.concatenate((sc_train, enctrain.values), axis=1)\n",
        "X = refclass\n",
        "\n",
        "# reshape target column to 1D array shape  \n",
        "c, r = cat_Ytest.values.shape\n",
        "y_test = cat_Ytest.values.reshape(c,)\n",
        "\n",
        "c, r = cat_Ytrain.values.shape\n",
        "y = cat_Ytrain.values.reshape(c,)\n",
        "\n",
        "# apply the random over-sampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_res, y_res = ros.fit_resample(X, y)\n",
        "print('Original dataset shape {}'.format(Counter(y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_res)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "fPwqq-eVrBGZ",
        "outputId": "02b13df0-11c2-4655-fd87-b61e0b2c5b80"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier();\n",
        "\n",
        "# fit random forest classifier on the training set\n",
        "rfc.fit(X_res, y_res);\n",
        "# extract important features\n",
        "score = np.round(rfc.feature_importances_,3)\n",
        "importances = pd.DataFrame({'feature':refclasscol,'importance':score})\n",
        "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
        "# plot importances\n",
        "plt.rcParams['figure.figsize'] = (11, 4)\n",
        "importances.plot.bar();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOqR20c2rBJ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "import itertools\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# create the RFE model and select 10 attributes\n",
        "rfe = RFE(rfc, n_features_to_select=10)\n",
        "rfe = rfe.fit(X_res, y_res)\n",
        "\n",
        "# summarize the selection of the attributes\n",
        "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), refclasscol)]\n",
        "selected_features = [v for i, v in feature_map if i==True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmiBdmywWRl_",
        "outputId": "eaeaec93-45ab-48f2-d563-d708409d9e2f"
      },
      "outputs": [],
      "source": [
        "selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8_IyxjpWVAa",
        "outputId": "44e1fe62-05a7-434b-9f48-89fe41c6ef0f"
      },
      "outputs": [],
      "source": [
        "# define columns to new dataframe\n",
        "newcol = list(refclasscol)\n",
        "newcol.append('attack_class')\n",
        "\n",
        "# add a dimension to target\n",
        "new_y_res = y_res[:, np.newaxis]\n",
        "\n",
        "# create a dataframe from sampled data\n",
        "res_arr = np.concatenate((X_res, new_y_res), axis=1)\n",
        "res_df = pd.DataFrame(res_arr, columns = newcol) \n",
        "\n",
        "# create test dataframe\n",
        "reftest = pd.concat([sc_testdf, testcat], axis=1)\n",
        "reftest['attack_class'] = reftest['attack_class'].astype(np.float64)\n",
        "reftest['protocol_type'] = reftest['protocol_type'].astype(np.float64)\n",
        "reftest['flag'] = reftest['flag'].astype(np.float64)\n",
        "reftest['service'] = reftest['service'].astype(np.float64)\n",
        "\n",
        "res_df.shape\n",
        "reftest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDe5njv8WVLg"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "classdict = defaultdict(list)\n",
        "\n",
        "# create two-target classes (normal class and an attack class)  \n",
        "attacklist = [('DoS', 0.0), ('Probe', 2.0), ('R2L', 3.0), ('U2R', 4.0)]\n",
        "normalclass = [('Normal', 1.0)]\n",
        "\n",
        "def create_classdict():\n",
        "    '''This function subdivides train and test dataset into two-class attack labels''' \n",
        "    for j, k in normalclass: \n",
        "        for i, v in attacklist: \n",
        "            restrain_set = res_df.loc[(res_df['attack_class'] == k) | (res_df['attack_class'] == v)]\n",
        "            classdict[j +'_' + i].append(restrain_set)\n",
        "            # test labels\n",
        "            reftest_set = reftest.loc[(reftest['attack_class'] == k) | (reftest['attack_class'] == v)]\n",
        "            classdict[j +'_' + i].append(reftest_set)\n",
        "        \n",
        "create_classdict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g98wKF3EWVN1"
      },
      "outputs": [],
      "source": [
        "for k, v in classdict.items():\n",
        "    k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z_ddSlOWVQb"
      },
      "outputs": [],
      "source": [
        "pretrain = classdict['Normal_DoS'][0]\n",
        "pretest = classdict['Normal_DoS'][1]\n",
        "grpclass = 'Normal_DoS'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCN5SZSReHpi"
      },
      "outputs": [],
      "source": [
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JojElGxWVTK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "Xresdf = pretrain \n",
        "newtest = pretest\n",
        "\n",
        "Xresdfnew = Xresdf[selected_features]\n",
        "Xresdfnum = Xresdfnew.drop(['service'], axis=1)\n",
        "Xresdfcat = Xresdfnew[['service']].copy()\n",
        "\n",
        "Xtest_features = newtest[selected_features]\n",
        "Xtestdfnum = Xtest_features.drop(['service'], axis=1)\n",
        "Xtestcat = Xtest_features[['service']].copy()\n",
        "\n",
        "\n",
        "# Fit train data\n",
        "enc.fit(Xresdfcat)\n",
        "\n",
        "# Transform train data\n",
        "X_train_1hotenc = enc.transform(Xresdfcat).tolist()\n",
        "\n",
        "       \n",
        "# Transform test data\n",
        "X_test_1hotenc = enc.transform(Xtestcat).tolist()\n",
        "\n",
        "\n",
        "X_train = np.concatenate((Xresdfnum.values, X_train_1hotenc), axis=1)\n",
        "X_test = np.concatenate((Xtestdfnum.values, X_test_1hotenc), axis=1) \n",
        "\n",
        "y_train = Xresdf[['attack_class']].copy()\n",
        "c, r = y_train.values.shape\n",
        "Y_train = y_train.values.reshape(c,)\n",
        "\n",
        "y_test = newtest[['attack_class']].copy()\n",
        "c, r = y_test.values.shape\n",
        "Y_test = y_test.values.reshape(c,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNElkio4WVVw"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC \n",
        "from sklearn.naive_bayes import BernoulliNB \n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Train KNeighborsClassifier Model\n",
        "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
        "KNN_Classifier.fit(X_train, Y_train); \n",
        "\n",
        "# Train LogisticRegression Model\n",
        "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0)\n",
        "LGR_Classifier.fit(X_train, Y_train);\n",
        "\n",
        "# Train Gaussian Naive Baye Model\n",
        "BNB_Classifier = BernoulliNB()\n",
        "BNB_Classifier.fit(X_train, Y_train)\n",
        "            \n",
        "# Train Decision Tree Model\n",
        "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "DTC_Classifier.fit(X_train, Y_train);\n",
        "            \n",
        "# Train RandomForestClassifier Model\n",
        "#RF_Classifier = RandomForestClassifier(criterion='entropy', n_jobs=-1, random_state=0)\n",
        "#RF_Classifier.fit(X_train, Y_train);  \n",
        "\n",
        "# Train SVM Model\n",
        "#SVC_Classifier = SVC(random_state=0)\n",
        "#SVC_Classifier.fit(X_train, Y_train)\n",
        "\n",
        "## Train Ensemble Model (This method combines all the individual models above except RandomForest)\n",
        "#combined_model = [('Naive Baye Classifier', BNB_Classifier), \n",
        "#                  ('Decision Tree Classifier', DTC_Classifier), \n",
        "#                  ('KNeighborsClassifier', KNN_Classifier), \n",
        "#                  ('LogisticRegression', LGR_Classifier)\n",
        "#                 ]\n",
        "#VotingClassifier =  VotingClassifier(estimators = combined_model,voting = 'soft', n_jobs=-1)\n",
        "#VotingClassifier.fit(X_train, Y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GmoRW_3WVYT",
        "outputId": "3a75fa7c-8375-4b62-ba3e-083be363c987"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "models = []\n",
        "#models.append(('SVM Classifier', SVC_Classifier))\n",
        "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
        "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
        "#models.append(('RandomForest Classifier', RF_Classifier))\n",
        "models.append(('KNeighborsClassifier', KNN_Classifier))\n",
        "models.append(('LogisticRegression', LGR_Classifier))\n",
        "#models.append(('VotingClassifier', VotingClassifier))\n",
        "\n",
        "for i, v in models:\n",
        "    scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
        "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
        "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
        "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
        "    print()\n",
        "    print('============================== {} {} Model Evaluation =============================='.format(grpclass, i))\n",
        "    print()\n",
        "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
        "    print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = []\n",
        "\n",
        "model.append(('Decision Tree Classifier', DTC_Classifier))\n",
        "\n",
        "\n",
        "for i, v in model:\n",
        "    scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
        "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
        "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
        "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
        "    print()\n",
        "    print('============================== {} {} Model Evaluation =============================='.format(grpclass, i))\n",
        "    print()\n",
        "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
        "    print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCOTbz00WVb3",
        "outputId": "313d1030-400e-427a-8741-41dd4db201e1"
      },
      "outputs": [],
      "source": [
        "for i, v in models:\n",
        "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
        "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
        "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
        "    print()\n",
        "    print('============================== {} {} Model Test Results =============================='.format(grpclass, i))\n",
        "    print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
